{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21590085",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "\n",
    "Link del respositorio: https://github.com/faguilarleal/lab3_vision \n",
    "\n",
    "#### Integrantes:\n",
    " - Francis Aguilar\n",
    " - César Lopez\n",
    " - Jose Marchena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e08a2b",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341486f1",
   "metadata": {},
   "source": [
    "<!-- En esta parte se busca que usted implemente un sistema de correspondencia completo. Para esto debe -->\n",
    "escribir un script en Python usando OpenCV. No se provee código base, debe estructurarlo usted mismx.\n",
    "Para esta parte debe crear su propia imagen a usar para esto:\n",
    "• Tome dos fotografías propias de un objeto con textura (i.e. una caja de cereral, una portada de\n",
    "libro, un edificio)\n",
    "• Foto 1: Vista frontal\n",
    "• Foto 2: Vista rotada (aproximadamente 45 grados) y con cambio de escala (aléjese o haga zoom).\n",
    "El cambio debe ser evidente\n",
    "Con esto haga lo siguiente en su código\n",
    "1. Cargue ambas imágenes en escala de grises\n",
    "2. Implemente la detección y descripción usando SIFT.\n",
    "3. Implemente la detección y descripción usando ORB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff1291b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error cargando una o ambas imágenes",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m img2 = cv2.imread(ruta_img2)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m img2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mError cargando una o ambas imágenes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n\u001b[32m     14\u001b[39m img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
      "\u001b[31mOSError\u001b[39m: Error cargando una o ambas imágenes"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ruta_img1 = \"foto_frontal.jpg\"\n",
    "ruta_img2 = \"foto_rotada.jpg\"\n",
    "\n",
    "img1 = cv2.imread(ruta_img1)\n",
    "img2 = cv2.imread(ruta_img2)\n",
    "\n",
    "if img1 is None or img2 is None:\n",
    "    raise IOError(\"Error cargando una o ambas imágenes\")\n",
    "\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "\n",
    "kp1_sift, des1_sift = sift.detectAndCompute(img1_gray, None)\n",
    "kp2_sift, des2_sift = sift.detectAndCompute(img2_gray, None)\n",
    "\n",
    "print(\"SIFT\")\n",
    "print(\"Imagen 1 - Keypoints:\", len(kp1_sift))\n",
    "print(\"Imagen 2 - Keypoints:\", len(kp2_sift))\n",
    "print(\"Descriptor img1:\", des1_sift.shape if des1_sift is not None else None)\n",
    "print(\"Descriptor img2:\", des2_sift.shape if des2_sift is not None else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create(nfeatures=5000)\n",
    "\n",
    "kp1_orb, des1_orb = orb.detectAndCompute(img1_gray, None)\n",
    "kp2_orb, des2_orb = orb.detectAndCompute(img2_gray, None)\n",
    "\n",
    "print(\"ORB\")\n",
    "print(\"Imagen 1 - Keypoints:\", len(kp1_orb))\n",
    "print(\"Imagen 2 - Keypoints:\", len(kp2_orb))\n",
    "print(\"Descriptor img1:\", des1_orb.shape if des1_orb is not None else None)\n",
    "print(\"Descriptor img2:\", des2_orb.shape if des2_orb is not None else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874da885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFMatcher para SIFT (norma L2)\n",
    "bf_sift = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "\n",
    "# KNN matching (k=2 para Lowe)\n",
    "matches_sift = bf_sift.knnMatch(des1_sift, des2_sift, k=2)\n",
    "\n",
    "# Lowe's Ratio Test\n",
    "good_matches_sift = []\n",
    "ratio_thresh = 0.75\n",
    "\n",
    "for m, n in matches_sift:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches_sift.append(m)\n",
    "\n",
    "print(\"SIFT Matching\")\n",
    "print(\"Matches totales:\", len(matches_sift))\n",
    "print(\"Good matches:\", len(good_matches_sift))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc384dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFMatcher para ORB (norma Hamming)\n",
    "bf_orb = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "# KNN matching\n",
    "matches_orb = bf_orb.knnMatch(des1_orb, des2_orb, k=2)\n",
    "\n",
    "# Lowe's Ratio Test\n",
    "good_matches_orb = []\n",
    "\n",
    "for m, n in matches_orb:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches_orb.append(m)\n",
    "\n",
    "print(\"ORB Matching\")\n",
    "print(\"Matches totales:\", len(matches_orb))\n",
    "print(\"Good matches:\", len(good_matches_orb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_matches_sift = cv2.drawMatches(\n",
    "    img1,\n",
    "    kp1_sift,\n",
    "    img2,\n",
    "    kp2_sift,\n",
    "    good_matches_sift,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    ")\n",
    "\n",
    "# Mostrar en Jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(cv2.cvtColor(img_matches_sift, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"SIFT - Good Matches (Lowe Ratio Test)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_matches_orb = cv2.drawMatches(\n",
    "    img1,\n",
    "    kp1_orb,\n",
    "    img2,\n",
    "    kp2_orb,\n",
    "    good_matches_orb,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(cv2.cvtColor(img_matches_orb, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"ORB - Good Matches (Lowe Ratio Test)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
